{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i bestestimator.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Rakuten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train = pd.read_csv(r\"C:\\Users\\jecombe\\OneDrive - Capgemini\\Notebooks\\Train.csv\", sep = ',')\n",
    "Target = pd.read_csv(r\"C:\\Users\\jecombe\\OneDrive - Capgemini\\Notebooks\\Target.csv\", sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>SHIPPING_MODE</th>\n",
       "      <th>SHIPPING_PRICE</th>\n",
       "      <th>WARRANTIES_FLG</th>\n",
       "      <th>WARRANTIES_PRICE</th>\n",
       "      <th>CARD_PAYMENT</th>\n",
       "      <th>COUPON_PAYMENT</th>\n",
       "      <th>RSP_PAYMENT</th>\n",
       "      <th>WALLET_PAYMENT</th>\n",
       "      <th>PRICECLUB_STATUS</th>\n",
       "      <th>...</th>\n",
       "      <th>BUYER_BIRTHDAY_DATE</th>\n",
       "      <th>BUYER_DEPARTMENT</th>\n",
       "      <th>BUYING_DATE</th>\n",
       "      <th>SELLER_SCORE_COUNT</th>\n",
       "      <th>SELLER_SCORE_AVERAGE</th>\n",
       "      <th>SELLER_COUNTRY</th>\n",
       "      <th>SELLER_DEPARTMENT</th>\n",
       "      <th>PRODUCT_TYPE</th>\n",
       "      <th>PRODUCT_FAMILY</th>\n",
       "      <th>ITEM_PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>UNSUBSCRIBED</td>\n",
       "      <td>...</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>34</td>\n",
       "      <td>3/2017</td>\n",
       "      <td>10000&lt;100000</td>\n",
       "      <td>46.0</td>\n",
       "      <td>FRANCE, METROPOLITAN</td>\n",
       "      <td>61</td>\n",
       "      <td>CELLPHONE_ACCESSORY</td>\n",
       "      <td>ELECTRONICS</td>\n",
       "      <td>&lt;10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>UNSUBSCRIBED</td>\n",
       "      <td>...</td>\n",
       "      <td>1952.0</td>\n",
       "      <td>77</td>\n",
       "      <td>8/2017</td>\n",
       "      <td>10000&lt;100000</td>\n",
       "      <td>45.0</td>\n",
       "      <td>FRANCE, METROPOLITAN</td>\n",
       "      <td>30</td>\n",
       "      <td>CELLPHONE_ACCESSORY</td>\n",
       "      <td>ELECTRONICS</td>\n",
       "      <td>&lt;10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>PLATINUM</td>\n",
       "      <td>...</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>58</td>\n",
       "      <td>5/2017</td>\n",
       "      <td>10000&lt;100000</td>\n",
       "      <td>43.0</td>\n",
       "      <td>CHINA</td>\n",
       "      <td>-1</td>\n",
       "      <td>TOYS</td>\n",
       "      <td>BABY</td>\n",
       "      <td>&lt;10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>RECOMMANDE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>5&lt;20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>UNSUBSCRIBED</td>\n",
       "      <td>...</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>31</td>\n",
       "      <td>5/2017</td>\n",
       "      <td>10000&lt;100000</td>\n",
       "      <td>44.0</td>\n",
       "      <td>FRANCE, METROPOLITAN</td>\n",
       "      <td>2</td>\n",
       "      <td>GARDEN_TOOLS</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>50&lt;100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>RECOMMANDE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PLATINUM</td>\n",
       "      <td>...</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>93</td>\n",
       "      <td>9/2017</td>\n",
       "      <td>1000&lt;10000</td>\n",
       "      <td>44.0</td>\n",
       "      <td>CHINA</td>\n",
       "      <td>-1</td>\n",
       "      <td>MODEL</td>\n",
       "      <td>BABY</td>\n",
       "      <td>1000&lt;5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>RECOMMANDE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SILVER</td>\n",
       "      <td>...</td>\n",
       "      <td>1987.0</td>\n",
       "      <td>31</td>\n",
       "      <td>9/2017</td>\n",
       "      <td>100000&lt;1000000</td>\n",
       "      <td>46.0</td>\n",
       "      <td>FRANCE, METROPOLITAN</td>\n",
       "      <td>72</td>\n",
       "      <td>TOYS</td>\n",
       "      <td>BABY</td>\n",
       "      <td>100&lt;500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>RECOMMANDE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>UNSUBSCRIBED</td>\n",
       "      <td>...</td>\n",
       "      <td>1986.0</td>\n",
       "      <td>66</td>\n",
       "      <td>1/2017</td>\n",
       "      <td>10000&lt;100000</td>\n",
       "      <td>45.0</td>\n",
       "      <td>HONG KONG</td>\n",
       "      <td>-1</td>\n",
       "      <td>BRICOLAGE</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>50&lt;100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>RECOMMANDE</td>\n",
       "      <td>5&lt;10</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>UNSUBSCRIBED</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78</td>\n",
       "      <td>4/2017</td>\n",
       "      <td>1000&lt;10000</td>\n",
       "      <td>44.0</td>\n",
       "      <td>FRANCE, METROPOLITAN</td>\n",
       "      <td>75</td>\n",
       "      <td>SHOES</td>\n",
       "      <td>CLOTHING</td>\n",
       "      <td>50&lt;100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>RECOMMANDE</td>\n",
       "      <td>10&lt;20</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>PLATINUM</td>\n",
       "      <td>...</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1/2017</td>\n",
       "      <td>1000&lt;10000</td>\n",
       "      <td>49.0</td>\n",
       "      <td>FRANCE, METROPOLITAN</td>\n",
       "      <td>75</td>\n",
       "      <td>VIDEO</td>\n",
       "      <td>VIDEO</td>\n",
       "      <td>100&lt;500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>NORMAL</td>\n",
       "      <td>&lt;1</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>UNSUBSCRIBED</td>\n",
       "      <td>...</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>57</td>\n",
       "      <td>8/2017</td>\n",
       "      <td>10000&lt;100000</td>\n",
       "      <td>48.0</td>\n",
       "      <td>FRANCE, METROPOLITAN</td>\n",
       "      <td>65</td>\n",
       "      <td>PLAY CARDS</td>\n",
       "      <td>GAMES</td>\n",
       "      <td>&lt;10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID SHIPPING_MODE SHIPPING_PRICE  WARRANTIES_FLG WARRANTIES_PRICE  \\\n",
       "0   0        NORMAL            NaN           False              NaN   \n",
       "1   1        NORMAL            NaN           False              NaN   \n",
       "2   2        NORMAL            NaN           False              NaN   \n",
       "3   3    RECOMMANDE            NaN            True             5<20   \n",
       "4   4    RECOMMANDE            NaN           False              NaN   \n",
       "5   5    RECOMMANDE            NaN           False              NaN   \n",
       "6   6    RECOMMANDE            NaN           False              NaN   \n",
       "7   7    RECOMMANDE           5<10           False              NaN   \n",
       "8   8    RECOMMANDE          10<20           False              NaN   \n",
       "9   9        NORMAL             <1           False              NaN   \n",
       "\n",
       "   CARD_PAYMENT  COUPON_PAYMENT  RSP_PAYMENT  WALLET_PAYMENT PRICECLUB_STATUS  \\\n",
       "0             1               0            1               0     UNSUBSCRIBED   \n",
       "1             1               0            0               0     UNSUBSCRIBED   \n",
       "2             0               0            0               1         PLATINUM   \n",
       "3             1               0            0               0     UNSUBSCRIBED   \n",
       "4             1               0            1               0         PLATINUM   \n",
       "5             1               0            0               0           SILVER   \n",
       "6             1               0            0               0     UNSUBSCRIBED   \n",
       "7             1               0            0               0     UNSUBSCRIBED   \n",
       "8             0               0            1               1         PLATINUM   \n",
       "9             1               0            0               0     UNSUBSCRIBED   \n",
       "\n",
       "     ...      BUYER_BIRTHDAY_DATE BUYER_DEPARTMENT  BUYING_DATE  \\\n",
       "0    ...                   1992.0               34       3/2017   \n",
       "1    ...                   1952.0               77       8/2017   \n",
       "2    ...                   1991.0               58       5/2017   \n",
       "3    ...                   1955.0               31       5/2017   \n",
       "4    ...                   1984.0               93       9/2017   \n",
       "5    ...                   1987.0               31       9/2017   \n",
       "6    ...                   1986.0               66       1/2017   \n",
       "7    ...                      NaN               78       4/2017   \n",
       "8    ...                   1960.0                1       1/2017   \n",
       "9    ...                   1993.0               57       8/2017   \n",
       "\n",
       "   SELLER_SCORE_COUNT SELLER_SCORE_AVERAGE        SELLER_COUNTRY  \\\n",
       "0        10000<100000                 46.0  FRANCE, METROPOLITAN   \n",
       "1        10000<100000                 45.0  FRANCE, METROPOLITAN   \n",
       "2        10000<100000                 43.0                 CHINA   \n",
       "3        10000<100000                 44.0  FRANCE, METROPOLITAN   \n",
       "4          1000<10000                 44.0                 CHINA   \n",
       "5      100000<1000000                 46.0  FRANCE, METROPOLITAN   \n",
       "6        10000<100000                 45.0             HONG KONG   \n",
       "7          1000<10000                 44.0  FRANCE, METROPOLITAN   \n",
       "8          1000<10000                 49.0  FRANCE, METROPOLITAN   \n",
       "9        10000<100000                 48.0  FRANCE, METROPOLITAN   \n",
       "\n",
       "   SELLER_DEPARTMENT         PRODUCT_TYPE  PRODUCT_FAMILY ITEM_PRICE  \n",
       "0                 61  CELLPHONE_ACCESSORY     ELECTRONICS        <10  \n",
       "1                 30  CELLPHONE_ACCESSORY     ELECTRONICS        <10  \n",
       "2                 -1                 TOYS            BABY        <10  \n",
       "3                  2         GARDEN_TOOLS           WHITE     50<100  \n",
       "4                 -1                MODEL            BABY  1000<5000  \n",
       "5                 72                 TOYS            BABY    100<500  \n",
       "6                 -1            BRICOLAGE           WHITE     50<100  \n",
       "7                 75                SHOES        CLOTHING     50<100  \n",
       "8                 75                VIDEO           VIDEO    100<500  \n",
       "9                 65           PLAY CARDS           GAMES        <10  \n",
       "\n",
       "[10 rows x 22 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>CLAIM_TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>DAMAGED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>NOT_RECEIVED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>WITHDRAWAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>UNDEFINED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>WITHDRAWAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID    CLAIM_TYPE\n",
       "0   0       DAMAGED\n",
       "1   1             -\n",
       "2   2  NOT_RECEIVED\n",
       "3   3             -\n",
       "4   4    WITHDRAWAL\n",
       "5   5             -\n",
       "6   6     UNDEFINED\n",
       "7   7    WITHDRAWAL\n",
       "8   8             -\n",
       "9   9             -"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Target.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### grid = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN data filled by 0 \n",
      "\n",
      "Searching for the best regressor on 10000 data using AUC loss... \n",
      "\n",
      "\n",
      " Bagging: 0.5433 (+/- 0.0048)\n",
      "\n",
      " Gradient Boosting: 0.5348 (+/- 0.0018)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " XGBoost: 0.5267 (+/- 0.0034)\n",
      "\n",
      " Random Forest: 0.5420 (+/- 0.0092)\n",
      "\n",
      " Decision Tree: 0.5383 (+/- 0.0035)\n",
      "\n",
      " Extra Tree: 0.5413 (+/- 0.0044)\n",
      "\n",
      " KNN: 0.5185 (+/- 0.0061)\n",
      "\n",
      " SVM: 0.5060 (+/- 0.0010)\n",
      "\n",
      " Best classifier : Bagging\n"
     ]
    }
   ],
   "source": [
    "clf = BestEstimator(Train, Target)\n",
    "\n",
    "clf.best_estim(type_esti='classifier',  # Type of estimator : classifier or regressor\n",
    "                   params=False,        # Allow to use a custom hyperparametres dict for GridSearCV\n",
    "                   ID='ID',             # ID feature of the DataFrame used\n",
    "                   target_ID=True,      # If Target feature have an ID\n",
    "                   cv=3,                # Numbers of folds for the first estimators check\n",
    "                   grid=False,           # if True, use a GridSearchCV with best estimator found\n",
    "                   hard_grid=False,     # if True, test huge combinaison of hyperparametres\n",
    "                   cv_grid=3,           # Number of folds for the GridSearchCV\n",
    "                   n=1000,             # Number of observations used for the first check\n",
    "                   n_grid=1000,         # Number of observations used for the GridSearchCV\n",
    "                   value=0,             # Value for fill NaN\n",
    "                   view_nan=False,      # if True check the NaN Data\n",
    "                   scoring='AUC')       # Type of scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import operator\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, GradientBoostingRegressor, \\\n",
    "    RandomForestRegressor\n",
    "from sklearn.svm import SVC, SVR\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.ensemble import ExtraTreesClassifier, ExtraTreesRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import BaggingClassifier, BaggingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "def multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(y_test)\n",
    "    y_test = lb.transform(y_test)\n",
    "    y_pred = lb.transform(y_pred)\n",
    "    return (roc_auc_score(y_test, y_pred, average=average))\n",
    "\n",
    "\n",
    "class BestEstimator(object):\n",
    "\n",
    "    def __init__(self, Data, Target):\n",
    "\n",
    "        self.Data = Data.copy()\n",
    "        self.Target = Target.copy()\n",
    "        self.dim_ = Data.shape\n",
    "\n",
    "        self.AUC = make_scorer(multiclass_roc_auc_score)\n",
    "\n",
    "    def best_estim(self,\n",
    "                   type_esti='classifier',  # Type of estimator : classifier or regressor\n",
    "                   params=False,  # Allow to use a custom hyperparametres dict for GridSearCV\n",
    "                   ID='ID',  # ID feature of the DataFrame used\n",
    "                   target_ID=True,  # If Target feature have an ID\n",
    "                   cv=3,  # Numbers of folds for the first estimators check\n",
    "                   grid=True,  # if True, use a GridSearchCV with best estimator found\n",
    "                   hard_grid=False,  # if True, test huge combinaison of hyperparametres\n",
    "                   cv_grid=3,  # Number of folds for the GridSearchCV\n",
    "                   n=10000,  # Number of observations used for the first check\n",
    "                   n_grid=10000,  # Number of observations used for the GridSearchCV\n",
    "                   value=0,  # Value for fill NaN\n",
    "                   view_nan=False,  # if True check the NaN Data\n",
    "                   scoring='mae'):  # Type of scorer\n",
    "\n",
    "        self.Data.drop([ID], axis=1, inplace=True)\n",
    "        if target_ID:\n",
    "            self.Target.drop([ID], axis=1, inplace=True)\n",
    "\n",
    "        if view_nan:\n",
    "            print(\"Missing Values :\\n\")\n",
    "\n",
    "            total = self.Data.isnull().sum().sort_values(ascending=False)\n",
    "            percent = (self.Data.isnull().sum() / self.Data.isnull().count()).sort_values(ascending=False) * 100\n",
    "            missing_data = pd.concat([total, percent], axis=1, keys=['Total', '%'])\n",
    "            print(\"{} \\n\".format(missing_data[(percent > 0)]))\n",
    "\n",
    "        if type(value) == int:\n",
    "            self.Data.fillna(value, inplace=True)\n",
    "            # self.Test.fillna(value, inplace = True)\n",
    "            # self.Missing_values()\n",
    "\n",
    "        elif value == 'bfill':\n",
    "            self.Data.fillna('bfill', inplace=True)\n",
    "            # self.Test.fillna('bfill', inplace = True)\n",
    "            # self.Missing_values()\n",
    "\n",
    "        elif value == 'ffill':\n",
    "            self.Data.fillna('ffill', inplace=True)\n",
    "            # self.Test.fillna('ffill', inplace = True)\n",
    "            # self.Missing_values()\n",
    "\n",
    "        if self.Data.isnull().any().any() == False:\n",
    "            print('NaN data filled by {} \\n'.format(value))\n",
    "        else:\n",
    "            print('Fail to fill NaN data')\n",
    "\n",
    "        for i in self.Data.columns:  ###########\n",
    "\n",
    "            if self.Data[i].dtype == object:\n",
    "                encoder = LabelEncoder()\n",
    "                encoder.fit(list(self.Data[i]))\n",
    "                self.Data[i] = encoder.transform(list(self.Data[i]))\n",
    "\n",
    "            if self.Data[i].dtype == float:\n",
    "                self.Data[i] = self.Data[i].astype('int')\n",
    "\n",
    "        for i in self.Target.columns:\n",
    "            if self.Target[i].dtype == object:\n",
    "                le = LabelEncoder()\n",
    "                le.fit(list(self.Target[i]))\n",
    "                self.Target[i] = le.transform(list(self.Target[i]))\n",
    "\n",
    "        X_tr, X_te, Y_tr, Y_te = train_test_split(self.Data, self.Target, random_state=0, test_size=1 / 3)\n",
    "\n",
    "        print('Searching for the best regressor on {} data using {} loss... \\n'.format(n, scoring))\n",
    "\n",
    "        if type_esti == 'classifier':\n",
    "\n",
    "            # print('\\n Searching for the best classifier on {} data... \\n'.format(n))\n",
    "\n",
    "            clfs = {}\n",
    "            clfs['Bagging'] = {'clf': BaggingClassifier(), 'name': 'Bagging'}\n",
    "            clfs['Gradient Boosting'] = {'clf': GradientBoostingClassifier(), 'name': 'Gradient Boosting'}\n",
    "            clfs['XGBoost'] = {'clf': XGBClassifier(), 'name': 'XGBoost'}\n",
    "            clfs['Random Forest'] = {'clf': RandomForestClassifier(n_estimators=100, n_jobs=-1),\n",
    "                                     'name': 'Random Forest'}\n",
    "            clfs['Decision Tree'] = {'clf': DecisionTreeClassifier(), 'name': 'Decision Tree'}\n",
    "            clfs['Extra Tree'] = {'clf': ExtraTreesClassifier(n_jobs=-1), 'name': 'Extra Tree'}\n",
    "\n",
    "            clfs['KNN'] = {'clf': KNeighborsClassifier(n_jobs=-1), 'name': 'KNN'}\n",
    "            # clfs['NN'] = {'clf': MLPClassifier(), 'name': 'MLPClassifier'\n",
    "            # clfs['LR'] = {'clf': LogisticClassifier(), 'name': 'LR'}\n",
    "            clfs['SVM'] = {'clf': SVC(gamma='auto'), 'name': 'SVM'}\n",
    "\n",
    "            for item in clfs:\n",
    "                Score = cross_val_score(clfs[item]['clf'], np.asarray(X_tr[0:n]), np.ravel(Y_tr[0:n]),\n",
    "                                        cv=cv, scoring=self.AUC)\n",
    "                Score_mean = Score.mean()\n",
    "                STD2 = Score.std() * 2\n",
    "\n",
    "                clfs[item]['score'] = Score  # roc_auc\n",
    "                clfs[item]['mean'] = Score_mean\n",
    "                clfs[item]['std2'] = STD2\n",
    "\n",
    "                print(\"\\n {}\".format(item + \": %0.4f (+/- %0.4f)\" % (clfs[item]['score'].mean(),\n",
    "                                                                     clfs[item]['score'].std() * 2)))\n",
    "\n",
    "            Best_clf = clfs[max(clfs.keys(), key=(lambda k: clfs[k]['mean']))]['name']\n",
    "\n",
    "\n",
    "        elif type_esti == 'regressor':\n",
    "\n",
    "            clfs = {}\n",
    "            clfs['Bagging'] = {'clf': BaggingRegressor(), 'name': 'Bagging'}\n",
    "            clfs['Gradient Boosting'] = {'clf': GradientBoostingRegressor(), 'name': 'Gradient Boosting'}\n",
    "            clfs['XGBoost'] = {'clf': XGBRegressor(), 'name': 'XGBoost'}\n",
    "            clfs['Random Forest'] = {'clf': RandomForestRegressor(n_estimators=100, n_jobs=-1),\n",
    "                                     'name': 'Random Forest'}\n",
    "            clfs['Decision Tree'] = {'clf': DecisionTreeRegressor(), 'name': 'Decision Tree'}\n",
    "            clfs['Extra Tree'] = {'clf': ExtraTreesRegressor(n_jobs=-1), 'name': 'Extra Tree'}\n",
    "            clfs['KNN'] = {'clf': KNeighborsRegressor(n_jobs=-1), 'name': 'KNN'}\n",
    "            # clfs['NN'] = {'clf': MLPClassifier(), 'name': 'MLPClassifier'\n",
    "            # clfs['LR'] = {'clf': LogisticClassifier(), 'name': 'LR'}\n",
    "            clfs['SVM'] = {'clf': SVR(gamma='auto'), 'name': 'SVM'}\n",
    "\n",
    "            for item in clfs:\n",
    "                # print(Y_tr[0:30])\n",
    "                Score = cross_val_score(clfs[item]['clf'], np.asarray(X_tr[0:n]), np.array(np.ravel(Y_tr[0:n])),\n",
    "                                        ########\"\"\n",
    "                                        cv=cv, scoring=scoring)\n",
    "                Score_mean = Score.mean()\n",
    "                STD2 = Score.std() * 2\n",
    "\n",
    "                clfs[item]['score'] = Score  # roc_auc\n",
    "                clfs[item]['mean'] = Score_mean\n",
    "                clfs[item]['std2'] = STD2\n",
    "\n",
    "                print(\"\\n {}\".format(item + \": %0.4f (+/- %0.4f)\" % (clfs[item]['score'].mean(),\n",
    "                                                                     clfs[item]['score'].std() * 2)))\n",
    "\n",
    "            Best_clf = clfs[max(clfs.keys(), key=(lambda k: clfs[k]['mean']))]['name']\n",
    "\n",
    "        if grid:\n",
    "            # print('grid = True')\n",
    "\n",
    "            if params == False:\n",
    "                # print('params = False')\n",
    "\n",
    "                # print(Best_clf)\n",
    "\n",
    "                if hard_grid == False:\n",
    "\n",
    "                    if Best_clf == 'Extra Tree':\n",
    "\n",
    "                        if type_esti == 'regressor':\n",
    "\n",
    "                            params = {'n_estimators': [100, 300, 600],\n",
    "                                      'criterion': ['mse', 'mae'],\n",
    "                                      'max_depth': [None, 5, 10]}\n",
    "\n",
    "                        else:\n",
    "\n",
    "                            params = {'n_estimators': [100, 300, 600],\n",
    "                                      'criterion': ['gini', 'entropy'],\n",
    "                                      'max_depth': [None, 5, 10]}\n",
    "\n",
    "                    if Best_clf == 'Gradient Boosting':\n",
    "\n",
    "                        if type_esti == 'regressor':\n",
    "\n",
    "                            params = {'n_estimators': [100, 300, 600],\n",
    "                                      'max_depth': [5, 10, None],\n",
    "                                      'learning_rate': [.001, .01, .1],\n",
    "                                      'loss': ['ls', 'lad']}\n",
    "                        else:\n",
    "\n",
    "                            params = {'n_estimators': [100, 300, 600],\n",
    "                                      'max_depth': [5, 10, None],\n",
    "                                      'learning_rate': [.001, .01, .1],\n",
    "                                      'loss': ['deviance', 'exponential']}\n",
    "\n",
    "\n",
    "                    elif Best_clf == 'Random Forest':\n",
    "                        #  print('Best_clf = dt ou rf')\n",
    "\n",
    "                        if type_esti == 'regressor':\n",
    "\n",
    "                            params = {'n_estimators': [10, 100, 300],\n",
    "                                      'max_depth': [5, 10, None],\n",
    "                                      'criterion': ['mse', 'mae']}\n",
    "\n",
    "                        else:\n",
    "\n",
    "                            params = {'n_estimators': [10, 100, 300],\n",
    "                                      'max_depth': [5, 10, None],\n",
    "                                      'criterion': ['gini', 'entropy']}\n",
    "\n",
    "                    elif Best_clf == 'Decision Tree':\n",
    "\n",
    "                        if type_esti == 'regressor':\n",
    "\n",
    "                            params = {'max_depth': [5, 10, 50, None],\n",
    "                                      'criterion': ['mse', 'friedman_mse', 'mae']}\n",
    "\n",
    "                        else:\n",
    "\n",
    "                            params = {'max_depth': [5, 10, 50, None],\n",
    "                                      'criterion': ['gini', 'entropy']}\n",
    "\n",
    "\n",
    "                    elif Best_clf == 'XGBoost':\n",
    "                        # print('Best_clf = xgb')\n",
    "\n",
    "                        params = {'eta': [.01, .1, .3],\n",
    "                                  'max_depth': [5, 10, None],\n",
    "                                  'gamma': [0, .1, .01]}\n",
    "\n",
    "                    elif Best_clf == 'Bagging':\n",
    "                        # print('best_clf = bag)')\n",
    "\n",
    "                        params = {'n_estimators': [100, 300, 600]}\n",
    "\n",
    "                    elif Best_clf == 'KNN':\n",
    "\n",
    "                        params = {'n_neighbors': [2, 5, 10, 30, 40],\n",
    "                                  'p': [1, 2]}\n",
    "\n",
    "                    elif Best_clf == 'SVM':\n",
    "\n",
    "                        params = {'C': {1, .5, .1, 5},\n",
    "                                  'tol': [.01, .001, .1, .0001]}\n",
    "\n",
    "\n",
    "\n",
    "                else:\n",
    "\n",
    "                    if Best_clf == 'Extra Tree':\n",
    "\n",
    "                        if type_esti == 'regressor':\n",
    "\n",
    "                            params = {'n_estimators': [10, 100, 300, 600, 1000, 1200],\n",
    "                                      'criterion': ['mae', 'mse'],\n",
    "                                      'max_depth': [None, 5, 10, 15, 20, 25]}\n",
    "\n",
    "                        else:\n",
    "\n",
    "                            params = {'n_estimators': [10, 100, 300, 600, 1000, 1200],\n",
    "                                      'criterion': ['gini', 'entropy'],\n",
    "                                      'max_depth': [None, 5, 10, 15, 20, 25]}\n",
    "\n",
    "                    if Best_clf == 'Gradient Boosting':\n",
    "\n",
    "                        if type_esti == 'regressor':\n",
    "\n",
    "                            params = {'n_estimators': [100, 300, 600, 1000, 1200],\n",
    "                                      'max_depth': [5, 10, 15, 25, None],\n",
    "                                      'learning_rate': [.001, .01, .1],\n",
    "                                      'loss': ['ls', 'lad', 'huber', 'quantile'],\n",
    "                                      'criterion': ['mse', 'friedman_mse']}\n",
    "                        else:\n",
    "\n",
    "                            params = {'n_estimators': [100, 300, 600, 1000, 1200],\n",
    "                                      'max_depth': [5, 10, 15, 25, None],\n",
    "                                      'learning_rate': [.001, .01, .1],\n",
    "                                      'loss': ['deviance', 'exponential'],\n",
    "                                      'criterion': ['mse', 'friedman_mse']}\n",
    "\n",
    "\n",
    "                    elif Best_clf == 'Random Forest':\n",
    "                        #  print('Best_clf = dt ou rf')\n",
    "\n",
    "                        if type_esti == 'regressor':\n",
    "\n",
    "                            params = {'n_estimators': [10, 100, 300, 600, 1000, 1200],\n",
    "                                      'max_depth': [5, 10, 15, 20, 25, None],\n",
    "                                      'criterion': ['mse', 'mae']}\n",
    "\n",
    "                        else:\n",
    "\n",
    "                            params = {'n_estimators': [10, 100, 300, 600, 1000, 1200],\n",
    "                                      'max_depth': [5, 10, 15, 20, 25, None],\n",
    "                                      'criterion': ['gini', 'entropy']}\n",
    "\n",
    "                    elif Best_clf == 'Decision Tree':\n",
    "\n",
    "                        if params == 'regressor':\n",
    "\n",
    "                            params = {'max_depth': [5, 10, 50, 100, None],\n",
    "                                      'criterion': ['mse', 'friedman_mse', 'mae'],\n",
    "                                      'splitter': ['best', 'random']}\n",
    "\n",
    "                        else:\n",
    "\n",
    "                            params = {'max_depth': [5, 10, 50, 100, None],\n",
    "                                      'criterion': ['gini', 'entropy'],\n",
    "                                      'splitter': ['best', 'random']}\n",
    "\n",
    "\n",
    "                    elif Best_clf == 'XGBoost':\n",
    "                        # print('Best_clf = xgb')\n",
    "\n",
    "                        params = {'eta': [0.001, .01, .1, .3, 1],\n",
    "                                  'max_depth': [5, 10, 15, 20, 25, None],\n",
    "                                  'gamma': [0, .1, .01, .001]}\n",
    "\n",
    "                    elif Best_clf == 'Bagging':\n",
    "                        # print('best_clf = bag)')\n",
    "\n",
    "                        params = {'n_estimators': [100, 300, 600, 1000, 1200, 1500]}\n",
    "\n",
    "                    elif Best_clf == 'KNN':\n",
    "\n",
    "                        params = {'n_neighbors': [2, 5, 10, 30, 40, 70, 100],\n",
    "                                  'p': [1, 2, 3]}\n",
    "\n",
    "                    elif Best_clf == 'SVM':\n",
    "\n",
    "                        params = {'C': {1, .5, .1, 5, .01, .001},\n",
    "                                  'tol': [.01, .001, .1, .0001, 1],\n",
    "                                  'kernel': ['rbf', 'linear', 'poly', 'sigmoid', 'precomputed']}\n",
    "\n",
    "            if hard_grid:\n",
    "                print('\\n Searching for the best hyperparametres of {} using hard_grid on {} data among : \\n'.format(\n",
    "                    Best_clf, n_grid))\n",
    "\n",
    "            else:\n",
    "                print('\\n Searching for the best hyperparametres of {} on {} data among : \\n'.format(Best_clf, n_grid))\n",
    "            print('{} \\n'.format(params))\n",
    "            # print('Starting GridSearchCV using {} Classifier with {} folds \\n'.format(Best_clf, cv_grid))\n",
    "\n",
    "            if scoring == 'AUC':\n",
    "                scoring = self.AUC\n",
    "                score = 'AUC'\n",
    "            else :\n",
    "                score = scoring\n",
    "\n",
    "            clf = clfs[max(clfs.keys(), key=(lambda k: clfs[k]['mean']))]['clf']\n",
    "            gr = GridSearchCV(clf, param_grid=params, cv=cv_grid, scoring=scoring, n_jobs=-1,\n",
    "                              verbose=1, refit=True, iid=True)  # ;\n",
    "\n",
    "            gr.fit(X_tr[0:n_grid], np.ravel(Y_tr[0:n_grid]))\n",
    "\n",
    "            # print(' Best score :', gr.best_score_,   '\\n Using these parametres :', gr.best_params_)\n",
    "\n",
    "            #####\n",
    "\n",
    "            print('\\n Finally, best estimator is : {} {}'.format(Best_clf, type_esti))\n",
    "            print('\\n Using these hyperparametres : {}'.format(gr.best_params_))\n",
    "\n",
    "           \n",
    "            print('\\n With this {} score : {}'.format(score, gr.best_score_))\n",
    "\n",
    "            # return (gr) !!!!!!!\n",
    "        else:\n",
    "            print('\\n Best {} : {}'.format(type_esti, Best_clf))\n",
    "\n",
    "    def grid(self, clf, params, cv=3, n=100000):\n",
    "\n",
    "        X_tr, X_te, Y_tr, Y_te = train_test_split(self.Data, self.Target, random_state=0, test_size=1 / 3)\n",
    "\n",
    "        gr = GridSearchCV(clf, param_grid=params, cv=cv, scoring=self.AUC, n_jobs=-1,\n",
    "                          verbose=1, refit=True, iid=True);\n",
    "\n",
    "        gr.fit(X_tr[0:n], np.ravel(Y_tr[0:n]))\n",
    "\n",
    "        # print(' Best score :', gr.best_score_,   '\\n Using this parametres :', gr.best_params_, '\\n With :', clf)\n",
    "        print(' Best score on Train:', gr.best_score_, '\\n Using this parametres :', gr.best_params_,\n",
    "              '\\n With : \\n {} '.format(clf))\n",
    "        return gr\n",
    "\n",
    "    def feature_eng(self, Test, value=0, ID='ID'):\n",
    "\n",
    "        Test.drop([ID], axis=1, inplace=True)\n",
    "\n",
    "        if type(value) == int:\n",
    "            Test.fillna(value, inplace=True)\n",
    "\n",
    "        elif value == 'bfill':\n",
    "            Test.fillna('bfill', inplace=True)\n",
    "\n",
    "        elif value == 'ffill':\n",
    "            Test.fillna('ffill', inplace=True)\n",
    "\n",
    "        for i in Test.columns:  ###########\n",
    "            if Test[i].dtype == float:\n",
    "                Test[i] = Test[i].astype('int')\n",
    "\n",
    "            elif Test[i].dtype == object:\n",
    "                encoder = LabelEncoder()\n",
    "                encoder.fit(list(Test[i]))\n",
    "                Test[i] = encoder.transform(list(Test[i]))\n",
    "\n",
    "    def pred(self, Test, gr, prob=False, same=True, ID='ID', value=0):  #\n",
    "\n",
    "        # Test.drop([ID], axis = 1, inplace = True)\n",
    "        Pred = pd.DataFrame()\n",
    "\n",
    "        if same == False:\n",
    "\n",
    "            Test.drop([ID], axis=1, inplace=True)\n",
    "\n",
    "            if type(value) == int:\n",
    "                Test.fillna(value, inplace=True)\n",
    "\n",
    "            elif value == 'bfill':\n",
    "                Test.fillna('bfill', inplace=True)\n",
    "\n",
    "            elif value == 'ffill':\n",
    "                Test.fillna('ffill', inplace=True)\n",
    "\n",
    "            for i in Test.columns:\n",
    "                if Test[i].dtype == float:\n",
    "                    Test[i] = Test[i].astype('int')\n",
    "\n",
    "                elif Test[i].dtype == object:\n",
    "                    encoder = LabelEncoder()\n",
    "                    encoder.fit(list(Test[i]))\n",
    "                    Test[i] = encoder.transform(list(Test[i]))\n",
    "\n",
    "        if prob == False:\n",
    "            # Pred[ID] = Test[ID]\n",
    "            Pred['Target'] = gr.predict(Test)\n",
    "            return (Pred)\n",
    "\n",
    "        else:\n",
    "            return (gr.predict_proba(Test))\n",
    "\n",
    "    # else :\n",
    "    #    return(gr.predict_proba(self.feature_eng(Data, value , ID)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN data filled by 0 \n",
      "\n",
      "Searching for the best regressor on 1000 data using AUC loss... \n",
      "\n",
      "\n",
      " Bagging: 0.5481 (+/- 0.0185)\n",
      "\n",
      " Gradient Boosting: 0.5406 (+/- 0.0059)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " XGBoost: 0.5363 (+/- 0.0175)\n",
      "\n",
      " Random Forest: 0.5395 (+/- 0.0092)\n",
      "\n",
      " Decision Tree: 0.5320 (+/- 0.0157)\n",
      "\n",
      " Extra Tree: 0.5357 (+/- 0.0214)\n",
      "\n",
      " KNN: 0.5176 (+/- 0.0046)\n",
      "\n",
      " SVM: 0.5029 (+/- 0.0040)\n",
      "\n",
      " Searching for the best hyperparametres of Bagging on 1000 data among : \n",
      "\n",
      "{'n_estimators': [100, 300, 600]} \n",
      "\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   9 out of   9 | elapsed:   15.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Finally, best estimator is : Bagging classifier\n",
      "\n",
      " Using these hyperparametres : {'n_estimators': 600}\n",
      "\n",
      " With this AUC score : 0.544291038804916\n"
     ]
    }
   ],
   "source": [
    "clf = BestEstimator(Train, Target)\n",
    "\n",
    "clf.best_estim(type_esti='classifier',  # Type of estimator : classifier or regressor\n",
    "                   params=False,        # Allow to use a custom hyperparametres dict for GridSearCV\n",
    "                   ID='ID',             # ID feature of the DataFrame used\n",
    "                   target_ID=True,      # If Target feature have an ID\n",
    "                   cv=3,                # Numbers of folds for the first estimators check\n",
    "                   grid=True,           # if True, use a GridSearchCV with best estimator found\n",
    "                   hard_grid=False,     # if True, test huge combinaison of hyperparametres\n",
    "                   cv_grid=3,           # Number of folds for the GridSearchCV\n",
    "                   n=1000,              # Number of observations used for the first check\n",
    "                   n_grid=1000,         # Number of observations used for the GridSearchCV\n",
    "                   value=0,             # Value for fill NaN\n",
    "                   view_nan=False,      # if True check the NaN Data\n",
    "                   scoring='AUC')       # Type of scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hard_Grid = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = BestEstimator(Train, Target)\n",
    "\n",
    "clf.best_estim(type_esti='classifier',  # Type of estimator : classifier or regressor\n",
    "                   params=False,        # Allow to use a custom hyperparametres dict for GridSearCV\n",
    "                   ID='ID',             # ID feature of the DataFrame used\n",
    "                   target_ID=True,      # If Target feature have an ID\n",
    "                   cv=3,                # Numbers of folds for the first estimators check\n",
    "                   grid=True,           # if True, use a GridSearchCV with best estimator found\n",
    "                   hard_grid=True,      # if True, test huge combinaison of hyperparametres\n",
    "                   cv_grid=3,           # Number of folds for the GridSearchCV\n",
    "                   n=10000,             # Number of observations used for the first check\n",
    "                   n_grid=1000,         # Number of observations used for the GridSearchCV\n",
    "                   value=0,             # Value for fill NaN\n",
    "                   view_nan=False,      # if True check the NaN Data\n",
    "                   scoring='AUC')       # Type of scorer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
