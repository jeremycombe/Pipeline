{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble des tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas \n",
    "import xgboost\n",
    "import numpy\n",
    "\n",
    "print('Pandas version :',pandas.__version__)\n",
    "print('Sklearn version :',sklearn.__version__)\n",
    "print('Xgboost version :',xgboost.__version__)\n",
    "print('Numpy version :',numpy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run -i BestEstimator.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Multi_Train = pd.read_csv(r\"C:\\Users\\jecombe\\OneDrive - Capgemini\\Notebooks\\Train.csv\", sep = ',')\n",
    "Multi_Target = pd.read_csv(r\"C:\\Users\\jecombe\\OneDrive - Capgemini\\Notebooks\\Target.csv\", sep = ';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coup d'oeil sur les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Multi_Train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Multi_Target.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fit method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lance le pipeline de choix d'estimateur et d'hyperparamètres optimaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Multi = BestEstimator(hard_grid=False)\n",
    "Multi.fit(Multi_Train, Multi_Target, scoring = 'accuracy') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All pred methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Multi.pred(Multi_Train[0:10], ID='ID', refit = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Multi.pred_grid(Multi_Train[0:10], ID='ID', value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prédiction des probabilités de chaque classe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### A partir du premier fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Multi.pred_grid_proba(Multi_Train[0:10], ID_Test = 'ID', ID_pred = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### En relançant un fit à partir du meilleur estimateur trouvé et de ses meilleurs hyperparamètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Multi.pred_proba(Multi_Train[0:10], ID_Test = 'ID', ID_pred = True, refit = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### best_size method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Permet d'évaluer l'erreur en fittant sur différent taille de Train ce qui permet de voir à quel moment apparait l'overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Multi.best_size(n=[2000, 5000, 15000, 25000], metric = 'accuracy_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Multi.best_size(n=[2000, 5000, 15000, 25000], metric = 'accuracy_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Multi.best_size(n=[200, 500, 1500, 2500], metric = 'accuracy_score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagg_fit method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Permet d'utiliser un Bagging sur le meilleur estimateur trouvé dans le fit method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Multi.Bagg_fit(Multi_Train, Multi_Target, n_estimators = [10,20,30],\n",
    "                 cv = 3, value = 0, ID = 'ID', metric = 'accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bin_Train = pd.read_csv(r\"C:\\Users\\jecombe\\OneDrive - Capgemini\\Notebooks\\Train1.csv\", sep = ';')\n",
    "target = pd.read_csv(r\"C:\\Users\\jecombe\\OneDrive - Capgemini\\Notebooks\\Target1.csv\", sep = ';')\n",
    "\n",
    "Bin_Target = pd.DataFrame()\n",
    "Bin_Target['ID'] = target['ID']\n",
    "Bin_Target['Target'] = [np.nan]*target.shape[0]\n",
    "\n",
    "\n",
    "for i in range(target.shape[0]):\n",
    "    if target['Target'][i] == 1:\n",
    "        Bin_Target['Target'][i] ='+'\n",
    "    else :\n",
    "        Bin_Target['Target'][i] ='-'\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bin_Train = pd.read_csv(r\"C:\\Users\\jecombe\\OneDrive - Capgemini\\Notebooks\\Train1.csv\", sep = ';')\n",
    "# Bin_Target = pd.read_csv(r\"C:\\Users\\jecombe\\OneDrive - Capgemini\\Notebooks\\Target1.csv\", sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bin_Train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bin_Target.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Bin = BestEstimator(type_esti = 'Classifier', hard_grid=True)\n",
    "Bin.fit(Bin_Train, Bin_Target, scoring = 'roc_auc') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All pred methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bin.pred_grid(Bin_Train[0:10], ID='ID', value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bin.pred(Bin_Train[0:10], ID='ID', value=0, refit = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bin.pred_grid_proba(Bin.Transform(Bin_Train[0:10]), ID = 'ID')\n",
    "Bin.pred_proba(Bin_Train[0:10], ID_Test = 'ID', ID_pred = True, refit = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bin.pred_grid_proba(Bin_Train[0:10], ID_Test = 'ID', ID_pred = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bin.best_size(n=[2000, 5000, 15000, 25000], metric = 'roc_auc_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bin.Bagg_fit(Bin_Train, Bin_Target, n_estimators = [10,20,30],\n",
    "                 cv = 3, value = 0, ID = 'ID', metric = 'roc_auc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Reg_Train = pd.read_csv(r\"C:\\Users\\jecombe\\OneDrive - Capgemini\\Notebooks\\input_training.csv\", sep = ';')\n",
    "Reg_Target = pd.read_csv(r\"C:\\Users\\jecombe\\OneDrive - Capgemini\\Notebooks\\Target_Engie.csv\", sep = ';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Reg_Target.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Reg_Train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Reg_Target.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fit method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%run -i Bestestimator_neg_fixed.py\n",
    "\n",
    "Reg = BestEstimator(type_esti = 'Regressor', hard_grid=True, grid = True)\n",
    "\n",
    "Reg.fit(Reg_Train, Reg_Target, scoring = 'neg_mean_absolute_error',view_nan = True, n = 1000, n_grid = 1000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reg.best_size(n=[100,200,300, 1000, 2000, 5000], metric = 'mean_absolute_error')\n",
    "Reg.best_size(n=[2000, 5000, 15000, 25000], metric = 'mean_absolute_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All pred methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Reg.pred(Reg_Train[0:10], ID='ID', refit = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Reg.pred_grid(Reg_Train[0:10], ID='ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagg_fit method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Reg.custom_grid(Reg_Train, Reg_Target, ID='ID', target_ID=True, n=1000, metric='mean_absolute_error', \n",
    "                params = {'eta': [0.001, .01],\n",
    "                              'max_depth': [5, 10],\n",
    "                              'gamma': [0, .1]}\n",
    ", cv=3, DF=None, value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Reg.Bagg_fit(Reg_Train, Reg_Target, n_estimators = [10,20,30],\n",
    "                 cv = 3, value = 0, ID = 'ID', metric = 'mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
